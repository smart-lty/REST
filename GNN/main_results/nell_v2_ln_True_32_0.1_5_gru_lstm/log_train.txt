============ Initialized logger ============
add_traspose_rels: True
aggregate: pna
aug: False
batch_size: 32
constrained_neg_prob: 0.0
dataset: nell_v2
dropout: 0.1
early_stop: 50
emb_dim: 32
enclosing_sub_graph: True
exp_dir: GNN/experiments/nell_v2_ln_True_32_0_5_gru_lstm_0.1
experiment_name: nell_v2_ln_True_32_0_5_gru_lstm_0.1
gpu: 4
hop: 3
l2: 0.0001
load_model: False
loss: bce
lr: 0.0005
main_dir: GNN
margin: 10
max_links: 1000000
message: gru
num_epochs: 10
num_gcn_layers: 5
num_neg_samples_per_link: 1
num_workers: 8
optimizer: Adam
train_file: train
un_hop: 1
update: lstm
using_jk: False
valid_file: valid
============================================
No existing model found. Initializing new model..
Device: cuda
Input dim : 32, # Relations : 176
Total number of parameters: 191777
Starting training ...
====================================================================================================
Epoch 1 Training Performance:{'auc': 0.9354405714439584, 'auc_pr': 0.9253486683781691, 'acc': 0.8546051831123007} in 650.1127297878265 s 
Epoch 1 Validation Performance:{'auc': 0.9163265042042904, 'auc_pr': 0.9039853717580071, 'acc': 0.678416485900217} in 43.67232322692871 s 
Epoch 1 Better models found w.r.t AUC-PR. Saved it!
Epoch 1 with loss: 0.3191098203223039, best validation AUC-PR: 0.9039853717580071, weight_norm: 14.240910530090332 in 693.8332993984222 s 
====================================================================================================
Epoch 2 Training Performance:{'auc': 0.9682100494462329, 'auc_pr': 0.9631061419502851, 'acc': 0.909843046599343} in 648.7136564254761 s 
Epoch 2 Validation Performance:{'auc': 0.9456753685518138, 'auc_pr': 0.9390835026696636, 'acc': 0.7635574837310195} in 43.36835026741028 s 
Epoch 2 Better models found w.r.t AUC-PR. Saved it!
Epoch 2 with loss: 0.22274791530482035, best validation AUC-PR: 0.9390835026696636, weight_norm: 13.197001457214355 in 692.1333990097046 s 
====================================================================================================
Epoch 3 Training Performance:{'auc': 0.9768751050765202, 'auc_pr': 0.973122400554788, 'acc': 0.9246867015452002} in 647.1528143882751 s 
Epoch 3 Validation Performance:{'auc': 0.9588905331708397, 'auc_pr': 0.956069738222209, 'acc': 0.838937093275488} in 43.101349115371704 s 
Epoch 3 Better models found w.r.t AUC-PR. Saved it!
Epoch 3 with loss: 0.18919035770607828, best validation AUC-PR: 0.956069738222209, weight_norm: 12.2675142288208 in 690.3048138618469 s 
====================================================================================================
Epoch 4 Training Performance:{'auc': 0.9799409820241932, 'auc_pr': 0.9770682656706537, 'acc': 0.9288234578415866} in 652.6617586612701 s 
Epoch 4 Validation Performance:{'auc': 0.9518865194498427, 'auc_pr': 0.9515259898216373, 'acc': 0.8373101952277657} in 42.59785485267639 s 
Epoch 4 with loss: 0.17585382906263441, best validation AUC-PR: 0.956069738222209, weight_norm: 11.42559814453125 in 695.3029179573059 s 
====================================================================================================
Epoch 5 Training Performance:{'auc': 0.9829483558589809, 'auc_pr': 0.9799613948154384, 'acc': 0.9369753011315245} in 648.6999793052673 s 
Epoch 5 Validation Performance:{'auc': 0.9491514956169037, 'auc_pr': 0.9486776256664149, 'acc': 0.8459869848156182} in 44.7617826461792 s 
Epoch 5 with loss: 0.15909142041368707, best validation AUC-PR: 0.956069738222209, weight_norm: 10.657074928283691 in 693.4997878074646 s 
====================================================================================================
Epoch 6 Training Performance:{'auc': 0.984673553740357, 'auc_pr': 0.9817255723160059, 'acc': 0.9408078841708237} in 656.8669807910919 s 
Epoch 6 Validation Performance:{'auc': 0.9495961575561944, 'auc_pr': 0.9485475083313526, 'acc': 0.8454446854663774} in 42.86351490020752 s 
Epoch 6 with loss: 0.14982933958390807, best validation AUC-PR: 0.956069738222209, weight_norm: 9.953680038452148 in 699.7718002796173 s 
====================================================================================================
Epoch 7 Training Performance:{'auc': 0.9876218101203604, 'auc_pr': 0.9855503700040285, 'acc': 0.9482297116437522} in 655.2298917770386 s 
Epoch 7 Validation Performance:{'auc': 0.9457612424183962, 'auc_pr': 0.9461295197683923, 'acc': 0.8627982646420824} in 42.98210120201111 s 
Epoch 7 with loss: 0.13393282842485357, best validation AUC-PR: 0.956069738222209, weight_norm: 9.310710906982422 in 698.2519669532776 s 
====================================================================================================
Epoch 8 Training Performance:{'auc': 0.9884731251547236, 'auc_pr': 0.9861704884894171, 'acc': 0.9512714442146246} in 653.9370951652527 s 
Epoch 8 Validation Performance:{'auc': 0.9437132095181182, 'auc_pr': 0.9464603684441765, 'acc': 0.8595444685466378} in 43.31558108329773 s 
Epoch 8 with loss: 0.1270334053248283, best validation AUC-PR: 0.956069738222209, weight_norm: 8.723616600036621 in 697.2908701896667 s 
====================================================================================================
Epoch 9 Training Performance:{'auc': 0.9893851046011826, 'auc_pr': 0.9869903308972079, 'acc': 0.954982357951089} in 653.1730289459229 s 
Epoch 9 Validation Performance:{'auc': 0.9390107330569684, 'auc_pr': 0.9417988382735406, 'acc': 0.824295010845987} in 43.2584707736969 s 
Epoch 9 with loss: 0.12009886928366548, best validation AUC-PR: 0.956069738222209, weight_norm: 8.188654899597168 in 696.468836069107 s 
====================================================================================================
Epoch 10 Training Performance:{'auc': 0.9908091195161601, 'auc_pr': 0.9888151496222147, 'acc': 0.9570507360992822} in 653.5575184822083 s 
Epoch 10 Validation Performance:{'auc': 0.9487056573232763, 'auc_pr': 0.947754616301127, 'acc': 0.8595444685466378} in 43.10862350463867 s 
Epoch 10 with loss: 0.1118093145076287, best validation AUC-PR: 0.956069738222209, weight_norm: 7.699355125427246 in 696.7060372829437 s 
====================================================================================================
